{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb75418c",
   "metadata": {},
   "source": [
    "# 필수 과제 (AI 챗봇 구현하기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d10b3",
   "metadata": {},
   "source": [
    "## 1.getpass를 이용하여 API키 불러오기\n",
    "\n",
    "- getpass는 파이썬 내장모듈로 따로 설치할 필요없이 import 해서 바로사용 가능\n",
    "- 패스워드를 입력할 때, 입력한 문자를 보여주지 않도록 해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a68c1a7-b59f-4c29-b20d-b261f902bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API key 입력:  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key 입력: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1857ba",
   "metadata": {},
   "source": [
    "## 2.모델 & 문서 로드하기\n",
    "\n",
    "- 인공지능산업최신동향을 선택한 이유는 최신동향을 이해하는게 이 산업에 몸담기 위해 조금이라도 도움이 될까싶어서 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091d1834-7527-42ca-bb07-8c87397adf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"/Users/t2023-m0072/Desktop/task/인공지능산업최신동향_2024년11월호.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44430a27",
   "metadata": {},
   "source": [
    "## 3. 문서 청크로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f669f-5a3b-46a9-a931-a5519a9b9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 청크로 나누기 방법 1\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits1 = text_splitter.split_documents(docs)\n",
    "\n",
    "print(splits1[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7bc9f",
   "metadata": {},
   "source": [
    "#### 청킹방식\n",
    "- CharacterTextSplitter : 주어진 텍스트를 문자 단위로 분할하는 데 사용된다. 아래의 방식과 유사하지만 보다 구체적인 구분을 위해 사용자 정의 구분 기호를 정의할 수 있는 기능이 있다. 기본적으로 \"\\n\\n\", \"\\n\", \" \", \"\"와 같은 문자로 분할을 시도한다.  \n",
    "#### 파라미터\n",
    "- separator : 분할된 각 청크를 구분할 때 기준이 되는 문자열이다. 기본값은 \"\\n\\n\" 이다.\n",
    "- chunk_size : 각 청크의 최대 길이이다. 여기서는 100으로 설정되어 있으므로, 최대 100자까지의 텍스트가 하나의 청크에 포함된다.\n",
    "- chunk_overlap : 인접한 청크 사이에 중복으로 포함될 문자의 수이다. 여기서는 10으로 설정되어 있으므로, 각 청크들은 연결 부분에서 10자가 중복된다. \n",
    "- length_function : 청크의 길이를 계산하는 함수이다. 여기서는 len 함수가 사용되었으므로, 문자열의 길이를 기반으로 청크의 길이를 계산한다.\n",
    "- is_separator_regex : 매개변수를 False로 설정하여 separator를 정규식이 아닌 일반 문자열로 처리합니다.\n",
    "- text_splitter를 사용해 텍스트를 문서로 분활한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531e460-bbbc-43a3-8437-89cad0f4f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 청크로 나누기 방법 2\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits2 = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "print(splits2[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d75d5c0",
   "metadata": {},
   "source": [
    "#### 청킹방식\n",
    "- 일반적인 텍스트에 권장되는 방식이다. 문자 목록을 매개변수로 받아 동작한다. 청크가 작아질 때까지 주어진 문자 목록의 순서대로 텍스트를 분할하려고 시도한다. 단락 -> 문자 -> 단어 순서로 재귀적으로 분할한다. 텍스트는 문자 목록 [\"\\n\\n\", \"\\n\", \" \", \"\"] 에 의해 분할 되고 청크 크기는 문자 수에 의해 측정된다. \n",
    "#### 파라미터는 위와 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c58d5",
   "metadata": {},
   "source": [
    "## 4.벡터 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d1d754-1c1e-48e3-8f35-23ccae394796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f148e7f",
   "metadata": {},
   "source": [
    "## 5.FAISS 벡터 스토어 생성 & Retriever로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "005d4aed-155d-40e0-b4cf-92e85be54f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=splits1, embedding=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce255794-4277-4db9-9272-6a3c3010c675",
   "metadata": {},
   "source": [
    "## 6.프롬프트 템플릿 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10165872-1a65-484e-9ad5-bdbfda87deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an ai expert. Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3618f",
   "metadata": {},
   "source": [
    "## 7.RAG 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9312ef9-b284-4dec-ac14-f30b09f7563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "class SimplePassThrough:\n",
    "    def invoke(self, inputs, **kwargs):\n",
    "        return inputs\n",
    "\n",
    "class ContextToPrompt:\n",
    "    def __init__(self, prompt_template):\n",
    "        self.prompt_template = prompt_template\n",
    "    \n",
    "    def invoke(self, inputs):\n",
    "        # 문서 내용을 텍스트로 변환\n",
    "        if isinstance(inputs, list):\n",
    "            context_text = \"\\n\".join([doc.page_content for doc in inputs])\n",
    "        else:\n",
    "            context_text = inputs\n",
    "        \n",
    "        # 프롬프트 템플릿에 적용\n",
    "        formatted_prompt = self.prompt_template.format_messages(\n",
    "            context=context_text,\n",
    "            question=inputs.get(\"question\", \"\")\n",
    "        )\n",
    "        return formatted_prompt\n",
    "\n",
    "# Retriever를 invoke() 메서드로 래핑하는 클래스 정의\n",
    "class RetrieverWrapper:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def invoke(self, inputs):\n",
    "        if isinstance(inputs, dict):\n",
    "            query = inputs.get(\"question\", \"\")\n",
    "        else:\n",
    "            query = inputs\n",
    "        # 검색 수행\n",
    "        response_docs = self.retriever.get_relevant_documents(query)\n",
    "        return response_docs\n",
    "\n",
    "llm_chain = LLMChain(llm=model, prompt=contextual_prompt)\n",
    "\n",
    "# RAG 체인 설정\n",
    "rag_chain_debug = {\n",
    "    \"context\": RetrieverWrapper(retriever),\n",
    "    \"prompt\": ContextToPrompt(contextual_prompt),\n",
    "    \"llm\": model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad625f3",
   "metadata": {},
   "source": [
    "## 8.챗봇 구동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ab1cf-63cb-4d94-87a1-96522a788a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 챗봇 구동\n",
    "while True:\n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 : \")\n",
    "    \n",
    "    # 1. Retriever로 관련 문서 검색\n",
    "    response_docs = rag_chain_debug[\"context\"].invoke({\"question\": query})\n",
    "    \n",
    "    # 2. 문서를 프롬프트로 변환\n",
    "    prompt_messages = rag_chain_debug[\"prompt\"].invoke({\n",
    "        \"context\": response_docs,\n",
    "        \"question\": query\n",
    "    })\n",
    "    \n",
    "    # 3. LLM으로 응답 생성\n",
    "    response = rag_chain_debug[\"llm\"].invoke(prompt_messages)\n",
    "    \n",
    "    print(\"\\n답변:\")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a1686-07dc-4904-9c87-70131b453761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_test",
   "language": "python",
   "name": "ai_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
